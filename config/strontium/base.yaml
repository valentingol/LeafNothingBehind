data:
  dataset_path: '../data'
  csv_name: 'train_regular.csv'
  grid_augmentation: true
dataloader:
  num_workers: 8
  batch_size: 32
  shuffle: true
  prefetch_factor: 2
model:
  sodium_config:
    pretrained: true
    run_id: 834358
    ae_config:  # U-Net-like architecture
      in_dim: 11  # 6 + 2*mask_embedding_channels + mlp_layers[-1]
      out_dim: 1
      layer_channels: [32, 64, 128]
      conv_per_layer: 2
      residual: true
      dropout_rate: 0.0
    mask_embedding_channels: 2
    mlp_layers: [2, 1]
  aluminium_config:
    pretrained: true
    run_id: 550160
    ae_config:  # U-Net-like architecture
      in_dim: 7  # 2 + 2*mask_emb + mlp_layers[-1]
      out_dim: 1
      layer_channels: [32, 64, 128]
      conv_per_layer: 2
      residual: true
      dropout_rate: 0.0
    mask_embedding_channels: 2
    mlp_layers: [2, 1]
  ae_config:
    in_dim: 64 # aluminium_config['layer_channels'][0] + sodium_config['layer_channels'][0]
    out_dim: 1
    layer_channels: [64, 128, 256]
    conv_per_layer: 2
    residual: true
    dropout_rate: 0.0


train:
  learning_rate: 0.001
  learning_rate_n_mult: 2  # number of times to decay lr (evenly spaced during the full training)
  learning_rate_decay: 0.2  # lr *= decay at each decay step
  n_epochs: 50
  log_interval: 20  # in iterations
  save_interval: 5  # in epochs
  interm_supervis: false  # intermediate supervision for AE
  weight_2: 0.03
  weight_3: 0.15
  start_from_pretrained: true
  pretrained_run_id: 16062002
  
